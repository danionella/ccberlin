<!doctype html>
<html class="no-js" lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">

    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Circuits Club Berlin</title>
    <link rel="stylesheet" href="css/foundation.css">
    <link rel="stylesheet" href="css/app.css">
  </head>
  <body>
    <!--TOPBAR -->

    <div class="cell small-6 right" data-sticky-container>
      <div class="sticky" data-sticky data-margin-top="0" data-sticky-on="small">
    <div class="top-bar" >
      <div class="top-bar-left">
        <ul class="dropdown menu" data-dropdown-menu>
          <li>
          <a href="index.html"><img src="img/logo.png" id="logo"/></a>
          <ul class="menu">
          <li><a href="index.html#next" id="menua">Next Circuits Club</a></li>
          <li><a href="index.html#speakers" id="menua">Speakers</a></li>
          <li><a href="index.html#about" id="menua">About</a></li>
          <li><a href="archive.html" id="menua">Past Circuit Clubs</a></li>
            <li><a href="dgsvo.html" id="menua">Legal Notice</a></li>
          </ul>
        </li>

        </ul>
      </div>
    </div>
    </div>
    </div>

<!--Content -->

<div class="grid-y">
  <div class="grid-x grid-padding-x">
    <div class="cell large-4 medium-6  small-12"  id="tile2">
    <h3> Vision in action: contextual signals in mouse visual cortex    </h3>
    <p class="next_speaker">Nathalie Rochefort</p>
  <p class="abstract">Neuronal representations in the primary visual cortex (V1) are shaped by experience, through the integration of both external visual inputs and internal signals related to an animal’s behaviour. The activity of V1 neurons is thus influenced by a variety of factors when animals navigate through their environment. Using in vivo two-photon calcium imaging, my research group examined the activity of V1 neurons before, during and after head-fixed mice were trained using a visually-guided task in a virtual reality environment. We found a refinement of responses to both visual aspects of the task as well as reward-related responses in V1. These results provide additional evidence that neuronal activity in primary sensory areas is highly dynamic and changes with the behavioural significance of sensory inputs. I will present current projects of the lab related to the mechanisms underlying this plasticity.</p>
    </div>


    <div class="cell large-4 medium-6  small-12"  id="tile1">
    <h3>  Neuronal algorithms for extracting multiple percepts from a single stimulus </h3>
      <p class="next_speaker">Mathew Diamond</p>

  <p class="abstract">When neuroscientists contemplate the coding of a tactile stimulus, it is natural for us to focus first on how the evoked neuronal activity underlies the perception of stimulus features. But a second percept accompanies the tactile experience – the feeling of time occupied by that stimulus. Logically, the “raw material” for both percepts must be the neuronal representation of the stimulus itself, and from this representation further streams of processing must lead to distinct percepts. We carried out psychophysical experiments in which human subjects and rats judged, on each trial, either the intensity of a vibration or the duration of a vibration. All subjects (both species) showed an interaction between the two percepts: a longer vibration feels stronger in intensity, and stronger feels longer. Further exploration of the interaction between the intensity and duration percepts allowed us to construct a computational framework whereby the vibration-evoked firing early in the processing stream is accumulated by two integrators, in parallel, each integrator giving rise to a distinct percept. Neuronal data from behaving rats seem to support this framework.</p>
      <div class="responsive-embed">
        <iframe height="800px" src="https://www.youtube.com/embed/u3UOjp7uGxU" frameborder="0" allowfullscreen></iframe>
      </div>
    </div>


    <div class="cell large-4 medium-6  small-12"  id="tile2">
    <h3>  New principles of cortico-thalamic interactions beyond sensory processing </h3>
      <p class="next_speaker">Michael Halassa</p>

  <p class="abstract">Interactions between the cortex and thalamus are critical for sensation, action and cognition. However, most of our understanding of these interactions is in the context of sensory processing. My lab has focused on cortico-thalamic loops that are non-sensory, allowing us to discover new principles of cortico-thalamic interactions beyond sensory processing. In my talk, I will show how the thalamus plays previously unrecognized roles in implementing cognitive control and flexibility, which involve rapid reconfiguration of task-relevant prefrontal representations</p>




  </div>
     
    <div class="cell large-4 medium-6  small-12"  id="tile2"> 
      <h3>How gravity shapes the neural representation of complex space</h3>
        <p class="next_speaker">Kate Jeffery </p>
    <p>(University College London)</p>
 
      <p class="abstract">Studies of the neural representation of space in rodents traversing simple, horizontally aligned laboratory environments have uncovered a network of brain areas that encode location (place cells), heading direction (head direction cells) and distance travelled (grid cells). However the real world is three dimensional, having hills and valleys, and in some cases offering the possibility for free movement in any direction and in any posture. This talk will look at the theoretical implications of this additional dimension, and present some neural data investigating how the spatial coding neurons react in non-horizontal space. Our conclusion is that the spatial map emerges from an interaction between two reference frames - the locomotor plane (the surface the animal is on) and the gravity vector.
</p>
          </div>
    </div>


    <script src="js/vendor/jquery.js"></script>
    <script src="js/vendor/what-input.js"></script>
    <script src="js/vendor/foundation.js"></script>
    <script src="js/app.js"></script>
  </body>
</html>
